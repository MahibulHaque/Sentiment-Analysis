{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_dataset_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MahibulHaque/Sentiment-Analysis/blob/main/toxic_dataset_sentiment_analysis.ipynb)"
      ],
      "metadata": {
        "id": "eOzG9u8yhslJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x02XhC0xQ6sz",
        "outputId": "c99b36b5-99c2-4d5d-c213-39bdd5a15d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-8515f5e1-9f07-d525-40e6-460f1206ad75)\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfdC947mRFy1",
        "outputId": "edc0ec81-c858-4cb7-b977-a6e6026daef0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-14 20:06:56--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-14 20:06:56 (107 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "LOfjoiFORNRF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Xike582iTgqw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/MahibulHaque/Sentiment-Analysis/main/data/toxic/train.csv\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/MahibulHaque/Sentiment-Analysis/main/data/toxic/test.csv\")"
      ],
      "metadata": {
        "id": "b8HB53IKSp4e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kFbam5eEUXut",
        "outputId": "7a735941-0125-4e8b-ad14-4d1dfca11726"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  Y\n",
              "119105  Geez, are you forgetful!  We've already discus...  0\n",
              "131631  Carioca RFA \\n\\nThanks for your support on my ...  0\n",
              "125326  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...  0\n",
              "111256  Pseudoscience category? \\n\\nI'm assuming that ...  0\n",
              "83590   (and if such phrase exists, it would be provid...  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbc5d45b-9017-4c1a-9ed2-6d7af4fc0347\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119105</th>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131631</th>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125326</th>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111256</th>\n",
              "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83590</th>\n",
              "      <td>(and if such phrase exists, it would be provid...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc5d45b-9017-4c1a-9ed2-6d7af4fc0347')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbc5d45b-9017-4c1a-9ed2-6d7af4fc0347 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbc5d45b-9017-4c1a-9ed2-6d7af4fc0347');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jZ5RR1PjUrN1",
        "outputId": "7eda191f-2554-4a09-cc07-4f37ad01f0f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  Y\n",
              "0  Thank you for understanding. I think very high...  0\n",
              "1                   :Dear god this site is horrible.  0\n",
              "2  \"::: Somebody will invariably try to add Relig...  0\n",
              "3  \" \\n\\n It says it right there that it IS a typ...  0\n",
              "4  \" \\n\\n == Before adding a new product to the l...  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6053e8c7-936c-4577-9a09-6c867319cdae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thank you for understanding. I think very high...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>:Dear god this site is horrible.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6053e8c7-936c-4577-9a09-6c867319cdae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6053e8c7-936c-4577-9a09-6c867319cdae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6053e8c7-936c-4577-9a09-6c867319cdae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.Y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LZMokdxUvv9",
        "outputId": "f983b1a5-a4fd-4971-ceb2-087c5b8ddacc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    144277\n",
              "1     15294\n",
              "Name: Y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(train_df['Y'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "eFcIXO1iU1eG",
        "outputId": "70a83190-0caf-4890-f7b4-17a810df55d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d45a20a10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "#create two different dataframe of majority and minority class \n",
        "df_majority = train_df[(train_df['Y']==0)] \n",
        "df_minority = train_df[(train_df['Y']==1)] \n",
        "# upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,    # sample with replacement\n",
        "                                 n_samples= 144277, # to match majority class\n",
        "                                 random_state=42)  # reproducible results\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_minority_upsampled, df_majority])"
      ],
      "metadata": {
        "id": "IUaMLiTTVu1V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df_upsampled['Y'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "aE_GZwM6WOr-",
        "outputId": "c2c91eb4-9de9-4f1b-b749-a0ded47ca28b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d458ec9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_upsampled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TTCyE1MzWYkW",
        "outputId": "8ea63e7e-4359-4390-9278-e66dee7a70af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  Y\n",
              "74761   \" (UTC)\\n\\nAnd what would you say otherwise? H...  1\n",
              "8708    You need psychological help, IP editor. The WP...  1\n",
              "55630                      So does your mouth, you gayass  1\n",
              "139968  sorry \\n\\ni stepped away for a second and my f...  1\n",
              "53262   African Black penis size compared to white pen...  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a025e316-feb0-4004-b1c3-ce158d666828\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74761</th>\n",
              "      <td>\" (UTC)\\n\\nAnd what would you say otherwise? H...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8708</th>\n",
              "      <td>You need psychological help, IP editor. The WP...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55630</th>\n",
              "      <td>So does your mouth, you gayass</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139968</th>\n",
              "      <td>sorry \\n\\ni stepped away for a second and my f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53262</th>\n",
              "      <td>African Black penis size compared to white pen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a025e316-feb0-4004-b1c3-ce158d666828')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a025e316-feb0-4004-b1c3-ce158d666828 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a025e316-feb0-4004-b1c3-ce158d666828');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_upsampled.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tCIUHeuuWb1e",
        "outputId": "bc3eabc9-20ec-463c-f28b-07ca2cb48207"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  Y\n",
              "159566  \":::::And for the second time of asking, when ...  0\n",
              "159567  You should be ashamed of yourself \\n\\nThat is ...  0\n",
              "159568  Spitzer \\n\\nUmm, theres no actual article for ...  0\n",
              "159569  And it looks like it was actually you who put ...  0\n",
              "159570  \"\\nAnd ... I really don't think you understand...  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77ada9fc-f6d6-4ff1-a50c-416c4ce03670\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77ada9fc-f6d6-4ff1-a50c-416c4ce03670')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77ada9fc-f6d6-4ff1-a50c-416c4ce03670 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77ada9fc-f6d6-4ff1-a50c-416c4ce03670');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = df_upsampled.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mrhiY9UwWfaG",
        "outputId": "1424bf91-69c0-464c-a9d7-8aa830ba1279"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  Y\n",
              "97136             kids incorporated \\n\\nSHUT THE HELL UP.  1\n",
              "136910  hello. fastlife deleted \\n\\nHey just wondering...  0\n",
              "58883   i read on the box of the game that broadband i...  0\n",
              "111496                           i removed eveyrthing. -)  0\n",
              "138488  Welcome!\\nHello, Jotunnorske, and welcome to W...  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32089989-8e84-41d8-a10c-23a01bf61818\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97136</th>\n",
              "      <td>kids incorporated \\n\\nSHUT THE HELL UP.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136910</th>\n",
              "      <td>hello. fastlife deleted \\n\\nHey just wondering...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58883</th>\n",
              "      <td>i read on the box of the game that broadband i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111496</th>\n",
              "      <td>i removed eveyrthing. -)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138488</th>\n",
              "      <td>Welcome!\\nHello, Jotunnorske, and welcome to W...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32089989-8e84-41d8-a10c-23a01bf61818')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32089989-8e84-41d8-a10c-23a01bf61818 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32089989-8e84-41d8-a10c-23a01bf61818');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(df_upsampled)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(df_upsampled) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygwWiO3GWoVG",
        "outputId": "7869a36d-a47a-4882-d557-542b2c818087"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 288554\n",
            "Total test samples: 63978\n",
            "Total samples: 352532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(df_upsampled)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"Y\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, Y = row\n",
        "  print(f\"Target: {Y}\", \"(toxic sentence)\" if Y > 0 else \"(not toxic)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbY96u1WW1XX",
        "outputId": "28ba475e-d41a-4427-ccd3-367f43c7540a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (toxic sentence)\n",
            "Text:\n",
            "Get a reality grip! \n",
            "\n",
            "You suck, try to be responsible and take youre elected resonability for real, and be objective...\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not toxic)\n",
            "Text:\n",
            "September 2008 (UTC)\n",
            "UPDATE: I did this.   03:49, 14\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (toxic sentence)\n",
            "Text:\n",
            ".\n",
            "\n",
            "Also! The interview where he claimed to be German he claimed to be German JEW, look it up to the idiot who keeps erasing my edit\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (toxic sentence)\n",
            "Text:\n",
            "You're an 38ass fuck43 \n",
            "\n",
            "3Go shit your pants43\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (toxic sentence)\n",
            "Text:\n",
            "You're cool\n",
            "\n",
            "You seem like a really cool guy... *bursts out laughing at sarcasm*.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"Y\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "metadata": {
        "id": "7x_JBo8XXMEp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH1VkiaPXVnx",
        "outputId": "b11d56e0-3d31-40b0-fe4e-db1994b5debc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(259698, 259698, 28856, 28856)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmj_Ib_OXYnR",
        "outputId": "e61e1836-d296-4a9b-c233-29e848d1d4f0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['By Finnish standards that wouldnt even be seen as an attack, but if that user felt bad about it tell him or her that im sorry (Not sure if my message got through), thats the way we talk here. Deal with it. Commie Soviet Union pigs had to learn the hard way too in WW2 between Finland and the evil empire. Also deal with the fact that all Lisa Williams had been sent to prison if these fucking hustlers had plotted shit like that in Finland.',\n",
              "        \"Yes, douche, but an article DOES have to be neutral.  Happyme22 has consistently been aggressiv in keeping the Nancy Reagan article skewed towards her favor.  If you check that article's talk page, you will see several admissions by him that he IS clearly in her favor, and that his edits to her article are aggressive in such a manner that there should be no question of his bias.  That you (and other adtiors/administrators) have been so lax in blocking him for making non-NPOV edits to her articleonly goes to prove -again- that Wikipedia is nothing more than a media manipulated brainwashing machine.  Fuck you, Wikipedai, you just lost a user ever.\\nYes, douche, but an article DOES have to be neutral.  Happyme22 has consistently been aggressiv in keeping the Nancy Reagan article skewed towards her favor.  If you check that article's talk page, you will see several admissions by him that he IS clearly in her favor, and that his edits to her article are aggressive in such a manner that there should be no question of his bias.  That you (and other adtiors/administrators) have been so lax in blocking him for making non-NPOV edits to her articleonly goes to prove -again- that Wikipedia is nothing more than a media manipulated brainwashing machine.  Fuck you, Wikipedai, you just lost a user ever.\\nYes, douche, but an article DOES have to be neutral.  Happyme22 has consistently been aggressiv in keeping the Nancy Reagan article skewed towards her favor.  If you check that article's talk page, you will see several admissions by him that he IS clearly in her favor, and that his edits to her article are aggressive in such a manner that there should be no question of his bias.  That you (and other adtiors/administrators) have been so lax in blocking him for making non-NPOV edits to her articleonly goes to prove -again- that Wikipedia is nothing more than a media manipulated brainwashing machine.  Fuck you, Wikipedai, you just lost a user ever.\\nYes, douche, but an article DOES have to be neutral.  Happyme22 has consistently been aggressiv in keeping the Nancy Reagan article skewed towards her favor.  If you check that article's talk page, you will see several admissions by him that he IS clearly in her favor, and that his edits to her article are aggressive in such a manner that there should be no question of his bias.  That you (and other adtiors/administrators) have been so lax in blocking him for making non-NPOV edits to her articleonly goes to prove -again- that Wikipedia is nothing more than a media manipulated brainwashing machine.  Fuck you, Wikipedai, you just lost a user ever.\",\n",
              "        \"Category:People from Brownsville, Kentucky\\n\\n:Category:People from Brownsville, Kentucky, which you created, has been nominated for possible deletion, merging, or renaming. If you would like to participate in the discussion, you are invited to add your comments at the category's entry on the Categories for discussion page. Thank you.\",\n",
              "        '\"::You\\'re right.  I wish there was more of an effort for people to include the correct information.  I see the \"\"feel free to add it yourself\"\" kind of stuff as an excuse to not have in included, but it is what it is, and I\\'ll be sure to use the correct terminology (rectums, anuses) instead of words like bootyholes in the actule article, since that would be inappropriate.    \\n\\n\"',\n",
              "        \"The Juggernaut, Bitch!! \\n\\nI think the line about the ...Juggernaut, Bitch!! skit is misplaced, or the heading is incorrect for the section it's contained in.  It has nothing to do with the comics. I agree that it is notable, however.\",\n",
              "        '\"\\n\\nPer WP:AE, you have been blocked indefinitely for persistent disruption to the project, including vandalism, disruptive editing and sock puppetry, as per Wikipedia:Requests for arbitration/Macedonia#Discretionary sanctions. If you believe this block is unjustified, please request one in the normal manner.  \\xa0(talk) \"',\n",
              "        '\"\\nHope everything has been going well. I am intrigued with all the Spanish garage rock bands you are editing on, I wasn\\'t aware there were that many. The only two I extensively gotten into are Los Bravos and Los Speakers. \\n\\nUnfortunately my work was impeded today by an IP-hopper who is determined to harass me, for weeks on end. All my pages have (again, for like the third time) been protected and the person said \"\"I have set the date on my calendar\"\" for when the protection ends. I think it\\'s rather childish, he gives me vulgar threats, even when I ask him to leave me to my work (I\\'m not sure what I did).  But, alas, he just quoted me and gave me a big NO, so on June 20th I should expect more sad threats. I told him to get a hobby, but I guess this is his hobby. Anyways, I got some work done and I hope I\\'m glad to see those Spanish band articles are being improved!  \"',\n",
              "        'fok you \\n\\nYOU SUK BITSH FOCK YOU',\n",
              "        'this lind is not a search engine. it is an archive of pictures. In my opinion is approppiate. i feel this is a valuable resource for cedar city history and an asset to the interested reader. i respect your opinion and appreciate leaving the link there. thank you.',\n",
              "        'FUCKING LAMER LOSTING OF MY TIME !!JOADFYH \\n\\nYou are wasting my time fucker. Please provide me the fucking information to add the fucking tag to add that this is my image, that I give it to everyone for free and that I owned the fucking copyright. THIS IS SO COMPLICATED TO DONATE AN IMAGE TO WIKIPEDIA THIS IS MY FUCKING SOURCE MY FUCKING IMAGE. fucker.'],\n",
              "       dtype=object), array([1, 1, 0, 0, 1, 0, 0, 1, 0, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "Wonderful! We've got a training set and a validation set containing Tweets and labels.\n",
        "\n",
        "Our labels are in numerical form (0 and 1) but our Tweets are in string form.\n",
        "\n",
        "🤔 Question: What do you think we have to do before we can use a machine learning algorithm with our text data?\n",
        "\n",
        "If you answered something along the lines of \"turn it into numbers\", you're correct. A machine learning algorithm requires its inputs to be in numerical form.\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "\n",
        "**Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
        "**Character-level tokenization**, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "**Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "**Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as `tf.keras.layers.Embedding`) and an embedding representation will be learned during model training.\n",
        "Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ],
      "metadata": {
        "id": "pKh3nl6bXbh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
        "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "metadata": {
        "id": "xiQGDtXOXwx-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3PfzXH0Yilu",
        "outputId": "f45febc8-17f5-4d0b-d042-04d6e0c422b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 40000 # max number of words to have in our vocabulary\n",
        "max_length = 60 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "WkpxQwEuYnN9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "9nE1wJlIYyhr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"I hate you!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFrubqprY540",
        "outputId": "8a24d9d7-9d95-4d5e-ef5b-4d07d1544afb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 60), dtype=int64, numpy=\n",
              "array([[ 6, 94,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAiGBctwZB82",
        "outputId": "a4fe1ca4-fe47-47a3-edd3-fe8ac6c97f42"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "hey jerk \n",
            "\n",
            "go write about gardening or britney spears or toby keith and FUCKING stop ruining articles on topics you have no damn clue about.      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 60), dtype=int64, numpy=\n",
              "array([[  264,  1000,    64,   349,    42, 26842,    30,  9414, 10206,\n",
              "           30, 14869,  4883,     7,    81,   114,  1284,   104,    18,\n",
              "         1550,     3,    20,    47,   269,  2218,    42,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgrisUVZHfv",
        "outputId": "d35b9858-978d-4227-c111-6ef426419c52"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 40000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'you', 'to']\n",
            "Bottom 5 least common words: ['greenman', 'greatful', 'grea', 'gratefully', 'grapple']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Embedding using an Embedding Layer\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. 1 = I, 2 = love, 3 = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the tf.keras.layers.Embedding layer.\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "input_dim - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "output_dim - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "embeddings_initializer - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "input_length - Length of sequences being passed to embedding layer.\n",
        "Knowing these, let's make an embedding layer"
      ],
      "metadata": {
        "id": "u0OzR2NcZQ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrxgpuNWZXcS",
        "outputId": "cc1d04bd-8b95-4e67-b193-d9e511f54029"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f0d458cd0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rXBJ3-wZa1p",
        "outputId": "02c9fe65-5c95-465a-83f7-7ef47c81d192"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Sory ToDST that was All My Roomates! They came in and Stormed my computer and Called You Gay! Which Your Not!      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 60, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03189236,  0.02247218,  0.0407537 , ..., -0.01647086,\n",
              "          0.04109469, -0.0499515 ],\n",
              "        [-0.01933004,  0.01307039, -0.01124482, ..., -0.03501333,\n",
              "          0.04731646, -0.02222626],\n",
              "        [-0.03508195,  0.01448471,  0.00513798, ...,  0.04485155,\n",
              "          0.03976364, -0.03543619],\n",
              "        ...,\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJBYmyDjZhcC",
        "outputId": "e1ec37ed-14fa-4e1a-b32b-628a1335af54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 0.03189236,  0.02247218,  0.0407537 , -0.01482048,  0.01244533,\n",
              "       -0.03970676, -0.01959174, -0.02130445, -0.01770921, -0.02340173,\n",
              "       -0.00583392, -0.02434   , -0.02275949, -0.0219172 , -0.00987709,\n",
              "       -0.04115373, -0.02982583,  0.04298922,  0.02964309, -0.00983932,\n",
              "        0.03929787, -0.00753308,  0.02947078,  0.00119908, -0.03825483,\n",
              "        0.00292561, -0.01190767,  0.00203359,  0.01753918, -0.03924812,\n",
              "       -0.00566458, -0.02361153,  0.02678504,  0.02090645,  0.0486042 ,\n",
              "       -0.02832842,  0.006573  , -0.02784554, -0.03836202,  0.02578933,\n",
              "       -0.02020677,  0.02955696,  0.01196317, -0.00851298, -0.0378455 ,\n",
              "       -0.00419575, -0.01113218, -0.03655435, -0.04364927,  0.00423124,\n",
              "        0.00054156, -0.0458966 , -0.02546015,  0.00946205,  0.03050101,\n",
              "        0.0432516 ,  0.03602627, -0.03990146, -0.00675676, -0.03765406,\n",
              "        0.00818088,  0.01394014,  0.03879924,  0.03497056, -0.00710266,\n",
              "        0.01743486,  0.0039641 , -0.02414931, -0.04029014, -0.04403204,\n",
              "       -0.00272517,  0.01966109, -0.00496085,  0.01809705, -0.03677652,\n",
              "        0.01052279,  0.04257293, -0.04970858, -0.04340742, -0.00969851,\n",
              "        0.01283128,  0.02161816, -0.02988265,  0.00992962, -0.04930954,\n",
              "        0.00738692,  0.02792839, -0.02161005,  0.03148622, -0.01844176,\n",
              "       -0.02473578,  0.0465749 , -0.04372753, -0.01614197, -0.00579915,\n",
              "       -0.01438017, -0.02359588, -0.04010499, -0.00598202,  0.03185498,\n",
              "        0.02496234, -0.04502305, -0.03482302, -0.03349356,  0.02764188,\n",
              "        0.03162011,  0.00859012,  0.04783389, -0.01361158,  0.02260716,\n",
              "       -0.02798044, -0.03693011,  0.00242054, -0.04815104, -0.04281848,\n",
              "        0.0471898 , -0.04160058, -0.01476098,  0.0188236 , -0.02341635,\n",
              "       -0.02831706, -0.00240855,  0.01678896, -0.0374248 , -0.00786235,\n",
              "       -0.01647086,  0.04109469, -0.0499515 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Baseline Model (Multinomial Naive Bayes)"
      ],
      "metadata": {
        "id": "BWFd1zF9Zkqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPZSc-jcZy5a",
        "outputId": "ce3b74f2-1a80-4258-a309-87627fb7791d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdGVfvGqZ1hB",
        "outputId": "61899676-e199-4146-e1e5-0e748f3a8adb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 91.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utkh9HyxZ-Zx",
        "outputId": "c6901266-d9b9-478c-c2fd-ac67185d9c4d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "FDd3gR2paCFJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbW4eosKaGPp",
        "outputId": "4b65c7f8-1205-462b-f268-d6b70cf06ab3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 91.91502633767674,\n",
              " 'f1': 0.9191042621078119,\n",
              " 'precision': 0.919645119138504,\n",
              " 'recall': 0.9191502633767674}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "OklNMor1aIhp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: LSTM\n",
        "With all this talk of what RNN's are and what they're good for, I'm sure you're eager to build one.\n",
        "\n",
        "We're going to start with an LSTM-powered RNN.\n",
        "\n",
        "To harness the power of the LSTM cell (LSTM cell and LSTM layer are often used interchangably) in TensorFlow, we'll use tensorflow.keras.layers.LSTM().\n",
        "\n",
        "Our model is going to take on a very similar structure to model_1:\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "The main difference will be that we're going to add an LSTM layer between our embedding and output.\n",
        "\n",
        "And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer (model_2_embedding) for our model. The text_vectorizer layer can be reused since it doesn't get updated during training.\n",
        "\n",
        "> 🔑 Note: The reason we use a new embedding layer for each model is since the embedding layer is a learned representation of words (as numbers), if we were to use the same embedding layer (embedding_1) for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."
      ],
      "metadata": {
        "id": "LCRPHX5HaLzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qLmEFI9aobE",
        "outputId": "6cd0e9d6-f079-4208-faf9-cf42be6cf88a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 60, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "G-7Q010Barsy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCkvfJW8aufi",
        "outputId": "15d855f2-8e68-4b1a-ebc1-9d327ae5d185"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 60)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 60, 128)           5120000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,169,473\n",
            "Trainable params: 5,169,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOSPo599awgi",
        "outputId": "71e6312b-72db-483c-c341-de07e5da7c9a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20220814-201051\n",
            "Epoch 1/5\n",
            "8116/8116 [==============================] - 88s 11ms/step - loss: 0.1310 - accuracy: 0.9543 - val_loss: 0.0899 - val_accuracy: 0.9697\n",
            "Epoch 2/5\n",
            "8116/8116 [==============================] - 89s 11ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0528 - val_accuracy: 0.9836\n",
            "Epoch 3/5\n",
            "8116/8116 [==============================] - 86s 11ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.0459 - val_accuracy: 0.9865\n",
            "Epoch 4/5\n",
            "8116/8116 [==============================] - 86s 11ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0322 - val_accuracy: 0.9915\n",
            "Epoch 5/5\n",
            "8116/8116 [==============================] - 85s 10ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0324 - val_accuracy: 0.9925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "metadata": {
        "id": "YbrZ37lUa0mJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db272660-2ca2-442f-ce5e-f4aefe3c7d63"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28856, 1), array([[9.9992788e-01],\n",
              "        [9.9996734e-01],\n",
              "        [2.1160315e-05],\n",
              "        [2.5595925e-06],\n",
              "        [2.1833459e-06],\n",
              "        [9.9990988e-01],\n",
              "        [9.9889034e-01],\n",
              "        [9.9997616e-01],\n",
              "        [9.9856395e-01],\n",
              "        [1.4081387e-03]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "id": "igMVInMtch9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6d85a3-104e-45a7-92d2-5a13eee76cfb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "SXY1Zg1kcndL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f8d734-1202-4aa0-a7db-4d203e92f4f4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 99.2479900194067,\n",
              " 'f1': 0.9924790118365551,\n",
              " 'precision': 0.9925478758595324,\n",
              " 'recall': 0.9924799001940671}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_2_results)"
      ],
      "metadata": {
        "id": "JTzokiC8crML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7b227e-0102-4465-d92b-002f9342bc45"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 91.92, New accuracy: 99.25, Difference: 7.33\n",
            "Baseline precision: 0.92, New precision: 0.99, Difference: 0.07\n",
            "Baseline recall: 0.92, New recall: 0.99, Difference: 0.07\n",
            "Baseline f1: 0.92, New f1: 0.99, Difference: 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "id": "UXKVn6rHcyiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6439f747-b396-43cc-a756-efff876b2555"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 91.92, New accuracy: 99.25, Difference: 7.33\n",
            "Baseline precision: 0.92, New precision: 0.99, Difference: 0.07\n",
            "Baseline recall: 0.92, New recall: 0.99, Difference: 0.07\n",
            "Baseline f1: 0.92, New f1: 0.99, Difference: 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: GRU (Gated Recurrent Unit)\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        ">📖 Resource: A full explanation of the GRU cell is beyond the scope of this noteook but I'd suggest the following resources to learn more:\n",
        "  * [Gated Recurrent Unit](https://en.wikipedia.org/wiki/Gated_recurrent_unit) Wikipedia page\n",
        "  * [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) by Simeon Kostadinov\n",
        "\n",
        "To use the GRU cell in TensorFlow, we can call the `tensorflow.keras.layers.GRU()` class.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "\n",
        "Again, the only difference will be the layer(s) we use between the embedding and the output."
      ],
      "metadata": {
        "id": "OglRAS8ec-R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "VGQCqsORdl6f"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LlHYGGd0du9n"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "ciXoGc_jeEuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae23373-3beb-4fe8-f42c-e6ea823c4fc9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 60)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 60, 128)           5120000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,157,313\n",
            "Trainable params: 5,157,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "metadata": {
        "id": "zj1w6GWgeHRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd8416f-7e4d-4a39-d5be-79b31c90ba67"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20220814-201819\n",
            "Epoch 1/5\n",
            "8116/8116 [==============================] - 90s 11ms/step - loss: 0.1470 - accuracy: 0.9428 - val_loss: 0.0704 - val_accuracy: 0.9773\n",
            "Epoch 2/5\n",
            "8116/8116 [==============================] - 93s 11ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0405 - val_accuracy: 0.9884\n",
            "Epoch 3/5\n",
            "8116/8116 [==============================] - 85s 10ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0393 - val_accuracy: 0.9898\n",
            "Epoch 4/5\n",
            "8116/8116 [==============================] - 104s 13ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0276 - val_accuracy: 0.9930\n",
            "Epoch 5/5\n",
            "8116/8116 [==============================] - 91s 11ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0277 - val_accuracy: 0.9936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "id": "BfSzML4PeMi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8ca2a7-2a5d-4682-9485-e3f31ed1e114"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28856, 1), array([[9.9992895e-01],\n",
              "        [9.9998963e-01],\n",
              "        [6.5449117e-06],\n",
              "        [4.1240730e-07],\n",
              "        [1.8752935e-07],\n",
              "        [9.9995053e-01],\n",
              "        [9.9989367e-01],\n",
              "        [9.9999726e-01],\n",
              "        [9.9998069e-01],\n",
              "        [4.6234438e-04]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "id": "FviLWAaLf6Qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d378c93d-4388-476b-dc4f-00d156a7f8b2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "B8e-dpy7f_Y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e717409d-e37e-4768-8972-a57c7d88f836"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 99.36235098419739,\n",
              " 'f1': 0.9936228295934573,\n",
              " 'precision': 0.9936817652062536,\n",
              " 'recall': 0.9936235098419739}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "id": "0AU-MIzogC2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbbccfd-7225-4542-e257-240996edba46"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 91.92, New accuracy: 99.36, Difference: 7.45\n",
            "Baseline precision: 0.92, New precision: 0.99, Difference: 0.07\n",
            "Baseline recall: 0.92, New recall: 0.99, Difference: 0.07\n",
            "Baseline f1: 0.92, New f1: 0.99, Difference: 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cm = confusion_matrix(val_labels, model_3_preds)\n",
        "cm "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImOR4U9ZBoQC",
        "outputId": "3132ac27-70fc-44fa-ae01-3f06a4e5176b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14055,   171],\n",
              "       [   13, 14617]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "plt.figure(figsize=(10, 10))\n",
        "sn.heatmap(cm, annot=True,fmt='d', cmap=\"Blues\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "_5YwIq4eB33R",
        "outputId": "2871f6a1-975f-41db-e1ed-3e900d3c8bfa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Actual')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: BERT\n",
        "\n",
        "BERT, which stands for Bidirectional Encoder Representations from Transformers, is based on Transformers, a deep learning model in which every output element is connected to every input element, and the weightings between them are dynamically calculated based upon their connection."
      ],
      "metadata": {
        "id": "eYTab727gF4-"
      }
    }
  ]
}